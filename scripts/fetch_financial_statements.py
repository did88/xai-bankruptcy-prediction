import os
import sys
import asyncio
import aiohttp
import pandas as pd
from pathlib import Path
from tqdm.asyncio import tqdm
import argparse

SRC_PATH = Path(__file__).resolve().parent.parent / "src"
sys.path.append(str(SRC_PATH))

from dart_bulk_downloader import (
    fetch_corp_codes,
    filter_kospi_kosdaq_non_financial,
    fetch_single_statement,
    RateLimiter,
)

PROGRESS_PATH = (
    Path(__file__).resolve().parent.parent
    / "data"
    / "raw"
    / "financial_statements_progress.csv"
)
PROGRESS_PATH.parent.mkdir(parents=True, exist_ok=True)
BATCH_SIZE = 100


def save_csv(df: pd.DataFrame, filename: str) -> None:
    out_dir = Path(__file__).resolve().parent.parent / "data" / "raw"
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / filename
    df.to_csv(path, index=False, encoding="utf-8-sig")
    print(f"ğŸ“ Saved {len(df):,} rows -> {path}")


async def main(reset: bool = False):
    api_key = os.getenv("DART_API_KEY")
    if not api_key:
        raise EnvironmentError("DART_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    if reset and PROGRESS_PATH.exists():
        PROGRESS_PATH.unlink()
        print("ğŸ—‘ï¸ ê¸°ì¡´ ì§„í–‰ íŒŒì¼ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    print("ğŸ“¥ ê¸°ì—… ì½”ë“œ ìˆ˜ì§‘ ì¤‘...")
    corp_df = await fetch_corp_codes(api_key)
    target_df = filter_kospi_kosdaq_non_financial(corp_df)
    corp_codes = target_df["corp_code"].unique().tolist()
    corp_name_map = dict(zip(target_df["corp_code"], target_df["corp_name"]))
    print(f"âœ… ë¹„ê¸ˆìœµ ìƒì¥ê¸°ì—… ìˆ˜: {len(corp_codes)}")

    years = list(range(2015, 2024))
    collected = []
    collected_keys = set()

    # ê¸°ì¡´ ìˆ˜ì§‘ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    if PROGRESS_PATH.exists():
        collected_df = pd.read_csv(PROGRESS_PATH, dtype=str)
        collected_keys = set(
            zip(
                collected_df["corp_code"],
                collected_df["bsns_year"],
                collected_df["fs_div"],
            )
        )
        collected = [collected_df]
        print(f"ğŸ“‹ ê¸°ì¡´ ìˆ˜ì§‘ëœ ë°ì´í„°: {len(collected_keys):,}ê°œ ì‘ì—… ì™„ë£Œ")
    else:
        print("ğŸ“‹ ìƒˆë¡œìš´ ìˆ˜ì§‘ ì‹œì‘")

    sem = asyncio.Semaphore(10)
    rate_limiter = RateLimiter(max_calls=500, period=60)
    stop_event = asyncio.Event()

    # ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—… ëª©ë¡ ìƒì„± (ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì€ ì‘ì—…ë§Œ)
    pending_tasks = []
    total_tasks = len(corp_codes) * len(years) * 2  # 2 = CFS, OFS

    for corp_code in corp_codes:
        for year in years:
            for fs_div in ["CFS", "OFS"]:
                key = (corp_code, str(year), fs_div)
                if key not in collected_keys:
                    pending_tasks.append((corp_code, year, fs_div))

    completed_tasks = total_tasks - len(pending_tasks)
    print(
        f"ğŸ“Š ì „ì²´ ì‘ì—…: {total_tasks:,}ê°œ / ì™„ë£Œ: {completed_tasks:,}ê°œ / ë‚¨ì€ ì‘ì—…: {len(pending_tasks):,}ê°œ"
    )

    if not pending_tasks:
        print("âœ… ëª¨ë“  ì‘ì—…ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ğŸš€ ë³‘ë ¬ ìˆ˜ì§‘ ì‹œì‘...")

    async def worker(session, corp_code, year, fs_div):
        if stop_event.is_set():
            return
        async with sem:
            try:
                df = await fetch_single_statement(
                    session, rate_limiter, api_key, corp_code, year
                )
            except RuntimeError as e:
                print(str(e))
                stop_event.set()
                return

        if stop_event.is_set():
            return

        if not df.empty:
            df["corp_name"] = corp_name_map.get(corp_code, "")
            df["corp_code"] = corp_code
            df["bsns_year"] = year
            df["fs_div"] = fs_div
            collected.append(df)

            header = not PROGRESS_PATH.exists()
            df.to_csv(
                PROGRESS_PATH,
                mode="a",
                header=header,
                index=False,
                encoding="utf-8-sig",
            )

        collected_keys.add((corp_code, str(year), fs_div))

    if pending_tasks:
        async with aiohttp.ClientSession() as session:
            for start in range(0, len(pending_tasks), BATCH_SIZE):
                if stop_event.is_set():
                    print("ğŸ“‰ ì¼ì¼ ì‚¬ìš©ëŸ‰ ì´ˆê³¼ë¡œ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break

                batch = pending_tasks[start : start + BATCH_SIZE]
                tasks = [
                    asyncio.create_task(worker(session, corp_code, year, fs_div))
                    for corp_code, year, fs_div in batch
                ]

                progress_desc = f"ì§„í–‰ë¥  ({completed_tasks:,}/{total_tasks:,} ì™„ë£Œ)"

                for f in tqdm(
                    asyncio.as_completed(tasks), total=len(tasks), desc=progress_desc
                ):
                    try:
                        await f
                    except asyncio.CancelledError:
                        pass

                    if stop_event.is_set():
                        for t in tasks:
                            t.cancel()
                        await asyncio.gather(*tasks, return_exceptions=True)
                        break

                if stop_event.is_set():
                    break

                completed_tasks += len(batch)

    if not collected:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    final_df = pd.concat(collected, ignore_index=True)

    # ë¶„ë¦¬ ë° ì €ì¥
    cfs_bs = final_df[(final_df["fs_div"] == "CFS") & (final_df["sj_div"] == "BS")]
    cfs_is = final_df[(final_df["fs_div"] == "CFS") & (final_df["sj_div"] == "IS")]
    ofs_bs = final_df[(final_df["fs_div"] == "OFS") & (final_df["sj_div"] == "BS")]
    ofs_is = final_df[(final_df["fs_div"] == "OFS") & (final_df["sj_div"] == "IS")]

    save_csv(cfs_bs, "ì—°ê²°ì¬ë¬´ì œí‘œ_ì¬ë¬´ìƒíƒœí‘œ.csv")
    save_csv(cfs_is, "ì—°ê²°ì¬ë¬´ì œí‘œ_ì†ìµê³„ì‚°ì„œ.csv")
    save_csv(ofs_bs, "ì¬ë¬´ì œí‘œ_ì¬ë¬´ìƒíƒœí‘œ.csv")
    save_csv(ofs_is, "ì¬ë¬´ì œí‘œ_ì†ìµê³„ì‚°ì„œ.csv")

    print("âœ… ì „ì²´ ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Download financial statements from DART"
    )
    parser.add_argument(
        "--reset",
        action="store_true",
        help="Ignore progress and download from scratch",
    )
    args = parser.parse_args()
    asyncio.run(main(reset=args.reset))
