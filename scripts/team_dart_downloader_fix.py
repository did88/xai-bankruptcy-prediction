import asyncio
import os
import time
from pathlib import Path
from typing import List, Tuple
import pandas as pd
from datetime import datetime
import argparse
import requests

from dart_bulk_downloader import (
    fetch_corp_codes,
    filter_kospi_kosdaq_non_financial,
    fetch_bulk_statements,
    save_to_excel,
    DART_SINGLE_ACCOUNT_URL,
)

# âœ… ë™ê¸° ìš”ì²­ì— ëŒ€í•œ ì´ˆë‹¹ 14~15íšŒ ì œí•œ í•¨ìˆ˜
def rate_limited_get(url, params, delay=0.07):
    time.sleep(delay)
    return requests.get(url, params=params, timeout=10)

# âœ… ìœ íš¨ ë³´ê³ ì„œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì—°ë„ë³„ ìˆœì°¨ ìš”ì²­ + ì œí•œ ì ìš©)
def has_report_for_any_year(api_key: str, corp_code: str, years: range) -> bool:
    for year in years:
        params = {
            "crtfc_key": api_key,
            "corp_code": corp_code,
            "bsns_year": year,
            "reprt_code": "11011",
        }
        try:
            resp = rate_limited_get(DART_SINGLE_ACCOUNT_URL, params)
            if resp.status_code == 200:
                data = resp.json()
                if data.get("status") == "000":
                    return True
        except Exception:
            continue
    return False

# âœ… ê¸°ì—…ì„ íŒ€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°
def split_corps_for_teams(corp_codes: List[str], chunk_size: int = 500) -> List[Tuple[int, List[str]]]:
    chunks = []
    for i in range(0, len(corp_codes), chunk_size):
        team_num = i // chunk_size + 1
        chunk = corp_codes[i:i + chunk_size]
        chunks.append((team_num, chunk))
    return chunks

# âœ… ê° íŒ€ë³„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
async def download_team_data(api_key: str, team_num: int, corp_codes: List[str], years: range, output_dir: Path, workers: int = 10) -> Path:
    print(f"ğŸš€ íŒ€ {team_num} ë‹¤ìš´ë¡œë“œ ì‹œì‘ - {len(corp_codes)}ê°œ ê¸°ì—…")
    start_time = datetime.now()

    statements = await fetch_bulk_statements(api_key, corp_codes, years, workers)
    filename = f"dart_statements_team_{team_num:02d}.xlsx"
    output_path = output_dir / filename
    save_to_excel(statements, output_path)

    elapsed = datetime.now() - start_time
    print(f"âœ… íŒ€ {team_num} ì™„ë£Œ - {elapsed.total_seconds():.1f}ì´ˆ ì†Œìš”")
    print(f"   ì €ì¥ ìœ„ì¹˜: {output_path}")
    print(f"   ë°ì´í„° í–‰ ìˆ˜: {len(statements):,}")
    return output_path

# âœ… íŒ€ë³„ íŒŒì¼ ë³‘í•©
def merge_team_files(team_files: List[Path], output_path: Path) -> None:
    print("\nğŸ“Š íŒ€ë³„ íŒŒì¼ ë³‘í•© ì¤‘...")
    all_data = []
    for file_path in sorted(team_files):
        if file_path.exists():
            df = pd.read_excel(file_path, engine='openpyxl')
            all_data.append(df)
            print(f"   - {file_path.name}: {len(df):,}í–‰")
    if all_data:
        merged_df = pd.concat(all_data, ignore_index=True)
        save_to_excel(merged_df, output_path)
        print(f"\nâœ… ë³‘í•© ì™„ë£Œ!")
        print(f"   ì „ì²´ ë°ì´í„°: {len(merged_df):,}í–‰")
        print(f"   ì €ì¥ ìœ„ì¹˜: {output_path}")
    else:
        print("âŒ ë³‘í•©í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# âœ… ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
async def main():
    parser = argparse.ArgumentParser(description='DART ì¬ë¬´ì œí‘œ íŒ€ë³„ ë‹¤ìš´ë¡œë“œ')
    parser.add_argument('--team', type=int, help='íŒ€ ë²ˆí˜¸ (1, 2, ...)')
    parser.add_argument('--merge-only', action='store_true', help='ë³‘í•©ë§Œ ìˆ˜í–‰')
    parser.add_argument('--list-teams', action='store_true', help='íŒ€ ë¶„í•  ì •ë³´ í‘œì‹œ')
    parser.add_argument('--workers', type=int, default=10, help='ë™ì‹œ ì‘ì—… ìˆ˜')
    parser.add_argument('--start-year', type=int, default=2015)
    parser.add_argument('--end-year', type=int, default=2022)
    args = parser.parse_args()

    if not args.team and not args.merge_only and not args.list_teams:
        print("\nì‚¬ìš©ë²•:")
        print(f"  python {Path(__file__).name} --list-teams")
        print(f"  python {Path(__file__).name} --team [íŒ€ë²ˆí˜¸]")
        print(f"  python {Path(__file__).name} --merge-only")
        return

    api_key = os.getenv("DART_API_KEY")
    if not api_key:
        raise EnvironmentError("DART_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”")

    output_dir = Path(__file__).resolve().parent.parent / "data" / "team_downloads"
    output_dir.mkdir(parents=True, exist_ok=True)

    print("ğŸ“‹ ê¸°ì—… ì½”ë“œ ëª©ë¡ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    corp_df = await fetch_corp_codes(api_key)
    target_df = filter_kospi_kosdaq_non_financial(corp_df)
    years = range(args.start_year, args.end_year + 1)

    print("\nğŸ“¤ ìœ íš¨í•œ ì‚¬ì—…ë³´ê³ ì„œê°€ ìˆëŠ” ê¸°ì—… í•„í„°ë§ ì¤‘...")
    valid_corp_codes = []
    for i, corp_code in enumerate(target_df["corp_code"]):
        if has_report_for_any_year(api_key, corp_code, years):
            valid_corp_codes.append(corp_code)
        if (i + 1) % 100 == 0:
            print(f"   ì§„í–‰ ì¤‘: {i + 1} / {len(target_df)}")

    print(f"âœ… ìœ íš¨ ê¸°ì—… ìˆ˜: {len(valid_corp_codes)}ê°œ")
    if len(valid_corp_codes) == 0:
        print("âŒ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_corp_codes = valid_corp_codes
    team_chunks = split_corps_for_teams(all_corp_codes, chunk_size=100)

    if args.list_teams:
        print("\nğŸ“Š íŒ€ë³„ í• ë‹¹ ì •ë³´:")
        for team_num, corps in team_chunks:
            print(f"   íŒ€ {team_num}: {len(corps)}ê°œ ê¸°ì—…")
        return

    if args.team:
        team_data = next((chunk for chunk in team_chunks if chunk[0] == args.team), None)
        if team_data:
            team_num, corp_codes = team_data
            print(f"\nğŸŒŸ íŒ€ {team_num} ë‹¤ìš´ë¡œë“œ ì„¤ì •:")
            print(f"   - ê¸°ì—… ìˆ˜: {len(corp_codes)}ê°œ")
            print(f"   - ì—°ë„: {args.start_year} ~ {args.end_year}")
            print(f"   - ì˜ˆìƒ ìš”ì²­ ìˆ˜: {len(corp_codes) * len(years):,}ê°œ")
            print(f"   - ë™ì‹œ ì‘ì—… ìˆ˜: {args.workers}")

            await download_team_data(
                api_key=api_key,
                team_num=team_num,
                corp_codes=corp_codes,
                years=years,
                output_dir=output_dir,
                workers=args.workers
            )
        else:
            print(f"âŒ íŒ€ {args.team} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(main())
