{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9800534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 [Random Forest]\n",
      "[[3411  162]\n",
      " [  45   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      3573\n",
      "           1       0.17      0.42      0.24        78\n",
      "\n",
      "    accuracy                           0.94      3651\n",
      "   macro avg       0.58      0.69      0.61      3651\n",
      "weighted avg       0.97      0.94      0.95      3651\n",
      "\n",
      "ROC-AUC: 0.8758674388397311\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 16901, number of negative: 16901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4080\n",
      "[LightGBM] [Info] Number of data points in the train set: 33802, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "📊 [LightGBM]\n",
      "[[3106  467]\n",
      " [  34   44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      3573\n",
      "           1       0.09      0.56      0.15        78\n",
      "\n",
      "    accuracy                           0.86      3651\n",
      "   macro avg       0.54      0.72      0.54      3651\n",
      "weighted avg       0.97      0.86      0.91      3651\n",
      "\n",
      "ROC-AUC: 0.8443220880248588\n"
     ]
    }
   ],
   "source": [
    "# 📦 라이브러리\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 📂 데이터 불러오기\n",
    "train_df = pd.read_csv('../../3_Post-Feature Engineering/YANG/train_data_with_smote.csv')\n",
    "val_df = pd.read_csv('../../3_Post-Feature Engineering/YANG/val_data.csv')\n",
    "\n",
    "# 🎯 X, y 분리\n",
    "X_train = train_df.drop(columns='is_defaulted')\n",
    "y_train = train_df['is_defaulted']\n",
    "X_val = val_df.drop(columns='is_defaulted')\n",
    "y_val = val_df['is_defaulted']\n",
    "\n",
    "# ✅ 1. Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 📈 예측 및 평가 (Random Forest)\n",
    "rf_preds = rf_model.predict(X_val)\n",
    "rf_probs = rf_model.predict_proba(X_val)[:, 1]\n",
    "print(\"📊 [Random Forest]\")\n",
    "print(confusion_matrix(y_val, rf_preds))\n",
    "print(classification_report(y_val, rf_preds))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_val, rf_probs))\n",
    "\n",
    "# ✅ 2. LightGBM\n",
    "lgb_model = LGBMClassifier(random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 📈 예측 및 평가 (LightGBM)\n",
    "lgb_preds = lgb_model.predict(X_val)\n",
    "lgb_probs = lgb_model.predict_proba(X_val)[:, 1]\n",
    "print(\"\\n📊 [LightGBM]\")\n",
    "print(confusion_matrix(y_val, lgb_preds))\n",
    "print(classification_report(y_val, lgb_preds))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_val, lgb_probs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
