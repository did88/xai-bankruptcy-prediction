{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기업 부도 예측 모델 (Random Forest & LightGBM)\n",
    "\n",
    "이 노트북은 한국 기업의 재무 데이터를 사용하여 부도 예측 모델을 구축합니다.\n",
    "- Random Forest\n",
    "- LightGBM\n",
    "\n",
    "두 모델의 성능을 비교하고 특성 중요도를 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치 (필요시 주석 해제)\n",
    "# !pip install lightgbm scikit-learn pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정 (matplotlib)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 시드 설정\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로딩 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "df = pd.read_csv('winsorized_data.csv')\n",
    "\n",
    "print(f\"데이터 shape: {df.shape}\")\n",
    "print(f\"\\n컬럼 수: {len(df.columns)}\")\n",
    "print(f\"\\n결측치 수:\")\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 정보 확인\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수 분포 확인\n",
    "print(\"부도 여부 분포:\")\n",
    "print(df['is_defaulted'].value_counts())\n",
    "print(f\"\\n부도율: {df['is_defaulted'].mean():.4f}\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['is_defaulted'].value_counts().plot(kind='bar')\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.xlabel('Is Defaulted (0: Normal, 1: Default)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 컬럼 제거 (인덱스, 회사명, 주식코드)\n",
    "features_to_drop = ['Unnamed: 0', 'corp_nm', 'stock_code']\n",
    "df_clean = df.drop(columns=features_to_drop)\n",
    "\n",
    "print(f\"전처리 후 shape: {df_clean.shape}\")\n",
    "print(f\"특성 개수: {len(df_clean.columns) - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 확인 및 처리\n",
    "missing_data = df_clean.isnull().sum()\n",
    "if missing_data.sum() > 0:\n",
    "    print(\"결측치가 있는 컬럼:\")\n",
    "    print(missing_data[missing_data > 0])\n",
    "    \n",
    "    # 결측치를 0으로 대체 (재무 데이터의 경우 0이 의미있을 수 있음)\n",
    "    df_clean = df_clean.fillna(0)\n",
    "    print(\"\\n결측치를 0으로 대체했습니다.\")\n",
    "else:\n",
    "    print(\"결측치가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무한대 값 확인 및 처리\n",
    "inf_cols = []\n",
    "for col in df_clean.columns:\n",
    "    if np.isinf(df_clean[col]).any():\n",
    "        inf_cols.append(col)\n",
    "\n",
    "if inf_cols:\n",
    "    print(f\"무한대 값이 있는 컬럼: {inf_cols}\")\n",
    "    # 무한대 값을 해당 컬럼의 최대값으로 대체\n",
    "    for col in inf_cols:\n",
    "        finite_values = df_clean[col][np.isfinite(df_clean[col])]\n",
    "        if len(finite_values) > 0:\n",
    "            max_val = finite_values.max()\n",
    "            df_clean[col] = df_clean[col].replace([np.inf, -np.inf], max_val)\n",
    "else:\n",
    "    print(\"무한대 값이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 특성과 타겟 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성과 타겟 분리\n",
    "X = df_clean.drop('is_defaulted', axis=1)\n",
    "y = df_clean['is_defaulted']\n",
    "\n",
    "print(f\"특성 개수: {X.shape[1]}\")\n",
    "print(f\"샘플 개수: {X.shape[0]}\")\n",
    "print(f\"타겟 분포: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성명 확인\n",
    "print(\"사용할 특성들:\")\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{i+1:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"훈련 데이터: {X_train.shape}\")\n",
    "print(f\"테스트 데이터: {X_test.shape}\")\n",
    "print(f\"훈련 데이터 부도율: {y_train.mean():.4f}\")\n",
    "print(f\"테스트 데이터 부도율: {y_test.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 기본 모델\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'  # 불균형 데이터 처리\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "print(\"Random Forest 모델 훈련 중...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"훈련 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 예측\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 성능 평가\n",
    "rf_auc = roc_auc_score(y_test, rf_pred_proba)\n",
    "print(f\"Random Forest AUC: {rf_auc:.4f}\")\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LightGBM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 모델\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    verbose=-1  # 로그 출력 억제\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "print(\"LightGBM 모델 훈련 중...\")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "print(\"훈련 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 예측\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "lgb_pred_proba = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 성능 평가\n",
    "lgb_auc = roc_auc_score(y_test, lgb_pred_proba)\n",
    "print(f\"LightGBM AUC: {lgb_auc:.4f}\")\n",
    "print(\"\\nLightGBM Classification Report:\")\n",
    "print(classification_report(y_test, lgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC 커브 비교\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Random Forest ROC\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_pred_proba)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {rf_auc:.4f})')\n",
    "\n",
    "# LightGBM ROC\n",
    "fpr_lgb, tpr_lgb, _ = roc_curve(y_test, lgb_pred_proba)\n",
    "plt.plot(fpr_lgb, tpr_lgb, label=f'LightGBM (AUC = {lgb_auc:.4f})')\n",
    "\n",
    "# 대각선 (랜덤 분류기)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 비교 표\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'LightGBM'],\n",
    "    'AUC': [rf_auc, lgb_auc]\n",
    "})\n",
    "\n",
    "print(\"모델 성능 비교:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "best_model = 'Random Forest' if rf_auc > lgb_auc else 'LightGBM'\n",
    "print(f\"\\n최고 성능 모델: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 특성 중요도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 특성 중요도\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Random Forest Top 15 특성 중요도:\")\n",
    "print(rf_importance.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 특성 중요도\n",
    "lgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"LightGBM Top 15 특성 중요도:\")\n",
    "print(lgb_importance.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 중요도 시각화\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Random Forest\n",
    "rf_top = rf_importance.head(15)\n",
    "ax1.barh(range(len(rf_top)), rf_top['importance'])\n",
    "ax1.set_yticks(range(len(rf_top)))\n",
    "ax1.set_yticklabels(rf_top['feature'])\n",
    "ax1.set_title('Random Forest - Top 15 Feature Importance')\n",
    "ax1.set_xlabel('Importance')\n",
    "\n",
    "# LightGBM\n",
    "lgb_top = lgb_importance.head(15)\n",
    "ax2.barh(range(len(lgb_top)), lgb_top['importance'])\n",
    "ax2.set_yticks(range(len(lgb_top)))\n",
    "ax2.set_yticklabels(lgb_top['feature'])\n",
    "ax2.set_title('LightGBM - Top 15 Feature Importance')\n",
    "ax2.set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 하이퍼파라미터 튜닝 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 하이퍼파라미터 튜닝 (시간이 오래 걸릴 수 있음)\n",
    "print(\"Random Forest 하이퍼파라미터 튜닝 중... (시간이 걸릴 수 있습니다)\")\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(f\"Best RF parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best RF CV score: {rf_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 하이퍼파라미터 튜닝\n",
    "print(\"LightGBM 하이퍼파라미터 튜닝 중...\")\n",
    "\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "lgb_grid = GridSearchCV(\n",
    "    lgb.LGBMClassifier(random_state=42, class_weight='balanced', verbose=-1),\n",
    "    lgb_param_grid,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgb_grid.fit(X_train, y_train)\n",
    "print(f\"Best LightGBM parameters: {lgb_grid.best_params_}\")\n",
    "print(f\"Best LightGBM CV score: {lgb_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 최종 결과 및 결론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화된 모델로 재평가\n",
    "rf_best_pred_proba = rf_grid.predict_proba(X_test)[:, 1]\n",
    "lgb_best_pred_proba = lgb_grid.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_best_auc = roc_auc_score(y_test, rf_best_pred_proba)\n",
    "lgb_best_auc = roc_auc_score(y_test, lgb_best_pred_proba)\n",
    "\n",
    "print(\"=== 최종 결과 ===\")\n",
    "print(f\"Random Forest (기본): AUC = {rf_auc:.4f}\")\n",
    "print(f\"Random Forest (튜닝): AUC = {rf_best_auc:.4f}\")\n",
    "print(f\"LightGBM (기본): AUC = {lgb_auc:.4f}\")\n",
    "print(f\"LightGBM (튜닝): AUC = {lgb_best_auc:.4f}\")\n",
    "\n",
    "best_auc = max(rf_auc, rf_best_auc, lgb_auc, lgb_best_auc)\n",
    "if best_auc == rf_best_auc:\n",
    "    best_model_name = \"Random Forest (튜닝)\"\n",
    "elif best_auc == lgb_best_auc:\n",
    "    best_model_name = \"LightGBM (튜닝)\"\n",
    "elif best_auc == rf_auc:\n",
    "    best_model_name = \"Random Forest (기본)\"\n",
    "else:\n",
    "    best_model_name = \"LightGBM (기본)\"\n",
    "\n",
    "print(f\"\\n최고 성능: {best_model_name} (AUC = {best_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 (선택사항)\n",
    "import joblib\n",
    "\n",
    "# 최고 성능 모델 저장\n",
    "if rf_best_auc >= lgb_best_auc:\n",
    "    joblib.dump(rf_grid.best_estimator_, 'best_model_rf.pkl')\n",
    "    print(\"Random Forest 모델을 'best_model_rf.pkl'로 저장했습니다.\")\n",
    "else:\n",
    "    joblib.dump(lgb_grid.best_estimator_, 'best_model_lgb.pkl')\n",
    "    print(\"LightGBM 모델을 'best_model_lgb.pkl'로 저장했습니다.\")\n",
    "\n",
    "print(\"\\n=== 분석 완료 ===\")\n",
    "print(\"부도 예측 모델링이 완료되었습니다.\")\n",
    "print(\"특성 중요도를 참고하여 어떤 재무 지표가 부도 예측에 중요한지 확인할 수 있습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}